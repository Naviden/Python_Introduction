{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T11:06:26.855781Z",
     "start_time": "2020-05-22T11:06:25.914967Z"
    }
   },
   "source": [
    "# Part I\n",
    "In this part you should answer the questions (or performing the requested tasks) using the **adult.csv** file you find in the *Data* folder. \n",
    "\n",
    "In case you want to learn more about this dataset : https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "\n",
    "Feel free to import any library you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the adult.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make sure that you're not loosing the first row!\n",
    "- Name the columns: \n",
    "'age',\n",
    "'workclass',\n",
    "'fnlwgt',\n",
    "'education',\n",
    "'education-num',\n",
    "'marital-status',\n",
    "'occupation',\n",
    "'relationship',\n",
    "'race',\n",
    "'sex',\n",
    "'capital-gain',\n",
    "'capital-loss',\n",
    "'hours-per-week',\n",
    "'native-country',\n",
    "'income'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:46.624059Z",
     "start_time": "2020-05-29T13:22:44.450526Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:46.719441Z",
     "start_time": "2020-05-29T13:22:46.627303Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/navid/Google Drive/active_python_files/Python_introduction/Data/adult.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:46.729699Z",
     "start_time": "2020-05-29T13:22:46.722809Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "              'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "              'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "              'native-country', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:46.779655Z",
     "start_time": "2020-05-29T13:22:46.737574Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove these columns: 'fnlwgt', 'education-num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:46.817156Z",
     "start_time": "2020-05-29T13:22:46.786983Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['fnlwgt', 'education-num'], inplace=True)\n",
    "#df.drop(['fnlwgt', 'education-num'], axis=1, inplace=False)\n",
    "\n",
    "#df = df.drop(['fnlwgt', 'education-num'], axis=1)\n",
    "#df.drop(['fnlwgt', 'education-num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all the records with capital-loss equal to 810 or 213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to reset the index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:46.855636Z",
     "start_time": "2020-05-29T13:22:46.819988Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[(df['capital-loss'] != 810) & (df['capital-loss'] != 213)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:46.893507Z",
     "start_time": "2020-05-29T13:22:46.864164Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report the missing data for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:47.660293Z",
     "start_time": "2020-05-29T13:22:47.638903Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:47.995364Z",
     "start_time": "2020-05-29T13:22:47.921964Z"
    }
   },
   "outputs": [],
   "source": [
    "a = 'a gf y d hj k v d h k v '.split()\n",
    "for i in tqdm(a):\n",
    "    print(i*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:48.527049Z",
     "start_time": "2020-05-29T13:22:48.422244Z"
    }
   },
   "outputs": [],
   "source": [
    "nan_count = [1 for x in tqdm(df['occupation']) if str(x) == 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:48.992560Z",
     "start_time": "2020-05-29T13:22:48.985868Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:49.480921Z",
     "start_time": "2020-05-29T13:22:49.435700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.replace(' ?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:49.920630Z",
     "start_time": "2020-05-29T13:22:49.835674Z"
    }
   },
   "outputs": [],
   "source": [
    "df['occupation'] = df['occupation'].apply(lambda x : x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:50.216677Z",
     "start_time": "2020-05-29T13:22:50.127148Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in tqdm(df['occupation']):\n",
    "    try:\n",
    "        temp.append(i.strip())\n",
    "        \n",
    "    except AttributeError:\n",
    "        temp.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:50.922044Z",
     "start_time": "2020-05-29T13:22:50.913667Z"
    }
   },
   "outputs": [],
   "source": [
    "df['occupation'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:22:55.701484Z",
     "start_time": "2020-05-29T13:22:55.688900Z"
    }
   },
   "outputs": [],
   "source": [
    "df['occupation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new column containing the average value of 'capital-gain' and 'capital-loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name the new column as *avg_capitial*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:23:00.228108Z",
     "start_time": "2020-05-29T13:22:56.710006Z"
    }
   },
   "outputs": [],
   "source": [
    "df['avg_capitial'] = sum([df['capital-gain'] + df['capital-loss']]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:23:00.249302Z",
     "start_time": "2020-05-29T13:23:00.230395Z"
    }
   },
   "outputs": [],
   "source": [
    "df['avg_capitial'] = np.mean([df['capital-gain'], df['capital-loss']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:23:01.719786Z",
     "start_time": "2020-05-29T13:23:00.251639Z"
    }
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df['avg_capitial'] = df.progress_apply(lambda row: np.mean([row['capital-gain'],\n",
    "                                                            row['capital-loss']]),\n",
    "                                                            axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:23:01.745881Z",
     "start_time": "2020-05-29T13:23:01.723041Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a scatter plot of 'age' and 'avg_capital'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:23:03.831481Z",
     "start_time": "2020-05-29T13:23:03.225680Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "plt.scatter(df.age, df.avg_capitial, alpha=0.3 )\n",
    "plt.title('Correlation between Age and Average Capital\\nMay 2020', fontsize=15)\n",
    "plt.xlabel('Age', fontsize= 12)\n",
    "plt.ylabel('Average Capital', fontsize= 12)\n",
    "plt.ylim(0, 60_000)\n",
    "#plt.savefig('Corr2020.png', dpi=600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T09:41:05.035006Z",
     "start_time": "2020-05-29T09:40:46.882544Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for country in df['native-country'].unique():\n",
    "    temp = df[df['native-country'] == country]\n",
    "    plt.scatter(temp.age, temp.avg_capitial, alpha=0.3 )\n",
    "    plt.title(f'Correlation between Age and Average Capital\\n{country}: May 2020', fontsize=15)\n",
    "    plt.xlabel('Age', fontsize=12)\n",
    "    plt.ylabel('Average Capital', fontsize=12)\n",
    "    plt.ylim(0, 60_000)\n",
    "    plt.savefig(f'Corr2020_{country}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the average 'capital-gain' for each country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas groupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:23:08.757255Z",
     "start_time": "2020-05-29T13:23:08.739463Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:24:27.220325Z",
     "start_time": "2020-05-29T13:24:27.191458Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['native-country','capital-gain']].groupby('native-country').mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function that given a column name prints the following info:\n",
    "- Number of Non-blank records\n",
    "- Data type\n",
    "- Average value (in case it's numerical)\n",
    "- Unique values (in case it's categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:33:21.262178Z",
     "start_time": "2020-05-29T13:33:21.255171Z"
    }
   },
   "outputs": [],
   "source": [
    "def column_info(col_name):\n",
    "    \"\"\"\n",
    "    Given the column name returns:\n",
    "    \n",
    "    - Number of Non-blank records\n",
    "    - Data type\n",
    "    - Average value (in case it's numerical)\n",
    "    - Unique values (in case it's categorical)\n",
    "    \"\"\"\n",
    "    print(f'Number of Non-blank records: {sum(~df[col_name].isna())}')\n",
    "    print(f'Data type: {df.dtypes[col_name].name}')\n",
    "    if df.dtypes[col_name].name in ('int64', 'float64'):\n",
    "        print(f'Average value: {round(df[col_name].mean(), 1)}')\n",
    "    if df.dtypes[col_name].name == 'object':\n",
    "        print('Unique values:')\n",
    "        print(df[col_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:33:30.936341Z",
     "start_time": "2020-05-29T13:33:30.916686Z"
    }
   },
   "outputs": [],
   "source": [
    "column_info('occupation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:33:47.319608Z",
     "start_time": "2020-05-29T13:33:47.305618Z"
    }
   },
   "outputs": [],
   "source": [
    "column_info('age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the final DataFrame both csv and Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('my_csv.csv', index=False)\n",
    "df.to_excel('my_csv.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II\n",
    "In this part each task is independent from the other parts.\n",
    "\n",
    "Feel free to import any library you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T11:47:11.369788Z",
     "start_time": "2020-05-22T11:47:11.347628Z"
    }
   },
   "source": [
    "## Write a function that for any given path print the following info:\n",
    "- Number of .py files\n",
    "- Number of .pdf files\n",
    "- Number of .csv files\n",
    "- Number of .xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:35:36.039754Z",
     "start_time": "2020-05-29T13:35:36.033806Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:40:48.987977Z",
     "start_time": "2020-05-29T13:40:48.972923Z"
    }
   },
   "outputs": [],
   "source": [
    "def file_report(path):\n",
    "    \"\"\"\n",
    "    prins the following for a given path\n",
    "    - Number of .py files\n",
    "    - Number of .pdf files\n",
    "    - Number of .csv files\n",
    "    - Number of .xlsx files\n",
    "    \"\"\"\n",
    "    files = glob(path)\n",
    "    py_files = [file for file in files if file.endswith('.py')]\n",
    "    pdf_files = [file for file in files if file.endswith('.pdf')]\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "    xlsx_files = [file for file in files if file.endswith('.xlsx')]\n",
    "    print(f'py files: {len(py_files)}')\n",
    "    print(f'pdf files: {len(pdf_files)}')\n",
    "    print(f'csv files: {len(csv_files)}')\n",
    "    print(f'xlsx files: {len(xlsx_files)}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:41:12.404587Z",
     "start_time": "2020-05-29T13:41:12.396988Z"
    }
   },
   "outputs": [],
   "source": [
    "file_report('/Users/navid/Google Drive/active_python_files/Python_introduction/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write a function that calculate the $A_L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T11:47:11.369788Z",
     "start_time": "2020-05-22T11:47:11.347628Z"
    }
   },
   "source": [
    "\n",
    "<img src=\"Images/lat_sur_area.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T11:47:11.369788Z",
     "start_time": "2020-05-22T11:47:11.347628Z"
    }
   },
   "source": [
    "- Use *isinstance* and *assert* to make sure the inputs are either integer or float\n",
    "- for 11, 7, 12 you should get **229.9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:11:53.400720Z",
     "start_time": "2020-05-29T10:11:53.385566Z"
    }
   },
   "outputs": [],
   "source": [
    "def lateral_surface_area(l, w, h):\n",
    "    \"\"\"\n",
    "    Docstring bla bla\n",
    "    \"\"\"\n",
    "    a = l * (((w / 2)**2+((h)**2)) ** 0.5)\n",
    "    b = w * (((l / 2)**2+((h)**2)) ** 0.5)\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:12:01.899333Z",
     "start_time": "2020-05-29T10:12:01.882194Z"
    }
   },
   "outputs": [],
   "source": [
    "lateral_surface_area(11, 7, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function that replaces spaces with _ in a given text while adds * before and after a specific letter (to be defined as the input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: 'Extraction was done by Barry Beckers from the 1994' given the letter **s** would results in--> 'Extraction_wa\\*s\\*_done_by_Barry_Becker\\*s\\*_from_the_1994'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:59:21.438671Z",
     "start_time": "2020-05-29T13:59:21.432604Z"
    }
   },
   "outputs": [],
   "source": [
    "def strange_format(text, letter):\n",
    "    \"\"\"\n",
    "    replaces spaces with _ in a given text while adds * before and after a specific letter\n",
    "    \"\"\"\n",
    "    return text.replace(' ','_').replace(letter, f'*{letter}*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:59:37.454451Z",
     "start_time": "2020-05-29T13:59:37.446894Z"
    }
   },
   "outputs": [],
   "source": [
    "strange_format('Extraction was done by Barry Beckers from the 1994', 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the 'review.txt' from *Data* folder :\n",
    "- Replace \"\" with ' (example: \"\"cidreira\"\" --> 'cidreira')\n",
    "- Lowercase the text\n",
    "- Count how many times a word is repeated in the text and put the results  a dictionary (example: {'a': 53, 'the': 34, ...})\n",
    "- using *os* library, remove the *review.txt*\n",
    "- Save the modified text to a file name *review_modified.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:55:24.727433Z",
     "start_time": "2020-05-29T13:55:24.717643Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "with open('Data/review.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "data = ' '.join(data)\n",
    "data = data.replace('\"\"', \"'\")\n",
    "cnt_dit = dict(Counter(data.split()))\n",
    "#os.remove('review.txt')\n",
    "with open('review_modified.txt', 'w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T13:22:38.169564Z",
     "start_time": "2020-05-22T13:22:38.151744Z"
    }
   },
   "source": [
    "## Using list comprehension, *'any'* built-in function and the given data:\n",
    "create a list of all dictionary keys that in their value there is at least one string with a length higher than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:31:32.469313Z",
     "start_time": "2020-05-29T10:31:32.458944Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {'first': ['a', 3, 'aa', 'bbb'],\n",
    "        'second': ['frigo', 77, 'fifo'],\n",
    "        'third': [11, 14, 976, 0.109, 'pippo']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:31:42.558916Z",
     "start_time": "2020-05-29T10:31:42.527727Z"
    }
   },
   "outputs": [],
   "source": [
    "# better version\n",
    "[k for k, v in data.items() if any([len(str(x)) > 3 for x in v])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:36:02.493814Z",
     "start_time": "2020-05-29T10:36:02.466384Z"
    }
   },
   "outputs": [],
   "source": [
    "# another version\n",
    "[k for k in data.keys() if any([len(str(x)) > 3 for x in data[k]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:23:14.714117Z",
     "start_time": "2020-05-29T10:23:14.696231Z"
    }
   },
   "outputs": [],
   "source": [
    "import re # regex\n",
    "\n",
    "a = 'my name is Navid and my cat name is oliver'\n",
    "\n",
    "[x.span() for x in re.finditer('name', a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:25:06.760213Z",
     "start_time": "2020-05-29T10:25:06.754905Z"
    }
   },
   "outputs": [],
   "source": [
    "# equal to the above list comprehension\n",
    "for i in re.finditer('name', a):\n",
    "    print(i.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:01:06.899372Z",
     "start_time": "2020-05-29T10:01:06.894190Z"
    }
   },
   "outputs": [],
   "source": [
    "A = ['a', 'B', 'a', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:04:35.986815Z",
     "start_time": "2020-05-29T10:04:35.956135Z"
    }
   },
   "outputs": [],
   "source": [
    "my_count = {}\n",
    "for i in A:\n",
    "    if i not in my_count.keys():\n",
    "        my_count[i] = 1\n",
    "        print(f'{i} --> {my_count}')\n",
    "    else:\n",
    "        my_count[i] += 1\n",
    "        print(f'{i} --> {my_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:05:27.299016Z",
     "start_time": "2020-05-29T10:05:27.271994Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:06:58.294427Z",
     "start_time": "2020-05-29T10:06:58.272549Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(Counter(df['native-country']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:07:25.449559Z",
     "start_time": "2020-05-29T10:07:25.405627Z"
    }
   },
   "outputs": [],
   "source": [
    "# An alternative\n",
    "df['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Quality Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to practice what we've learned with this dataset! [Download link](https://bit.ly/38KRxc7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2) and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.\n",
    "This dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "0 Date (DD/MM/YYYY)\n",
    "1 Time (HH.MM.SS)\n",
    "2 True hourly averaged concentration CO in mg/m^3 (reference analyzer)\n",
    "3 PT08.S1 (tin oxide) hourly averaged sensor response (nominally CO targeted)\n",
    "4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)\n",
    "5 True hourly averaged Benzene concentration in microg/m^3 (reference analyzer)\n",
    "6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)\n",
    "7 True hourly averaged NOx concentration in ppb (reference analyzer)\n",
    "8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted)\n",
    "9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)\n",
    "10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\n",
    "11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)\n",
    "12 Temperature in Â°C\n",
    "13 Relative Humidity (%)\n",
    "14 AH Absolute Humidity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file we downloaded is a zip file. Let use **zipfile** library that is come with Python and you don't need to install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure you're in the directory of the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the zip file \n",
    "with ZipFile('AirQualityUCI.zip', 'r') as obj:\n",
    "    obj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we've extracted the zip file we can read it with pandas\n",
    "df = pd.read_csv('AirQualityUCI.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we've extracted the zip file we can read it with pandas\n",
    "df = pd.read_csv('AirQualityUCI.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[list(df.columns)[:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns seem ok now. what about the end of the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! there are lots of **NaN** values there!\n",
    "we can use **.dropna** method to remove them. pay attention to the **how='all'** argument. It means _remove rows that **all** of their values are NaN_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the dataset info , we fond out that the creators used **-200** to fill the blanks. We should replace these values with real *Nan*s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(-200, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok we've correctly identified the *NaN* values but how much *NaN*s we have now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened above? first we used **.isna()** method to check each value in the DataFrame to see if it's *NaN* . This returns a New DataFrame with just *True* and *False* values(*True* if the value is *NaN* and *False* if it's not a *NaN*). Then we use **.sum()** to add them up. You may not expected Python to sum *True/False* (Boolean) values but the reason it happens is that Python sees *True* as 1 and *False* as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, at the end of the data cleaning, we can save our cleaned data to a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Results/AirQuality_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write two function for the given formulas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/sphere.png\" width=\"700\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function *(get_sphere_volume)* should get **5** and return **523.6**\n",
    "\n",
    "The first function *(get_sphere_radius)* should get **17** and return **1.6**\n",
    "\n",
    "hint: for $\\pi$ use *math.pi* (import math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_sphere_volume(radius):\n",
    "    return (4/3) * (math.pi * (radius ** 3))\n",
    "\n",
    "def get_sphere_radius(volume):\n",
    "    return (3 * (volume / (4 * math.pi))) ** (1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
